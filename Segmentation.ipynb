{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edae295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "def get_train_augs():\n",
    "  return A.Compose([\n",
    "        A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5)\n",
    "  ])\n",
    "\n",
    "def get_valid_augs():\n",
    "  return A.Compose([\n",
    "        A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "  ])  \n",
    "class SegmentationDataset(Dataset):\n",
    "\n",
    "  def __init__(self,df,augmentations):\n",
    "    \n",
    "    self.df = df\n",
    "    self.augmentations = augmentations\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "\n",
    "    row = self.df.iloc[idx]\n",
    "\n",
    "    image_path = row.images\n",
    "    mask_path = row.masks\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) #(h,w,c)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    if self.augmentations:\n",
    "      data = self.augmentations(image=image, mask=mask)\n",
    "      image = data[\"image\"]\n",
    "      mask= data[\"mask\"]\n",
    "\n",
    "    #(h,w,c)->(c,h,w)\n",
    "\n",
    "    image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
    "    mask= np.transpose(mask, (2,0,1)).astype(np.float32)\n",
    "\n",
    "    image = torch.Tensor(image)/255.0\n",
    "    mask = torch.round(torch.Tensor(mask)/255.0)\n",
    "    \n",
    "    return image,mask\n",
    "trainset = SegmentationDataset(train_df,get_train_augs())\n",
    "validset = SegmentationDataset(valid_df,get_valid_augs())\n",
    "\n",
    "idx=3\n",
    "\n",
    "image,mask = trainset[idx]\n",
    "#helper.show_image(image,mask)\n",
    "helper.imshow(image)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle= True)\n",
    "validloader = DataLoader(validset, batch_size=BATCH_SIZE)\n",
    "print(f\"total no. of batches in trainloader : {len(trainloader)}\")\n",
    "print(f\"total no. of batches in validloader : {len(validloader)}\")\n",
    "for image, mask in trainloader:\n",
    "  break\n",
    "\n",
    "print(f\"One batch image shape: {image.shape}\")\n",
    "print(f\"One batch mask shape: {mask.shape}\")\n",
    "\n",
    "from torch import nn\n",
    "import segmentation_models_pytorch as smp \n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "\n",
    "from torch import nn\n",
    "import segmentation_models_pytorch as smp \n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "\n",
    "class SegmentationModel(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(SegmentationModel, self).__init__()\n",
    "\n",
    "    self.arc = smp.Unet(\n",
    "        encoder_name = ENCODER,\n",
    "        encoder_weights = WEIGHTS,\n",
    "        in_channels=3,\n",
    "        classes = 1,\n",
    "        activation=None\n",
    "    )\n",
    "\n",
    "  def forward(self, images,mask=None):\n",
    "\n",
    "    logits = self.arc(images)\n",
    "\n",
    "    if mask != None:\n",
    "      loss1 = DiceLoss(mode=\"binary\")(logits,mask)\n",
    "      loss2= nn.BCEWithLogitsLoss()(logits,mask)\n",
    "      return logits, loss1*loss2\n",
    "\n",
    "    return logits\n",
    "model = SegmentationModel()\n",
    "model.to(DEVICE);\n",
    "\n",
    "def train_fn(data_loader, model, optimizer):\n",
    "\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "\n",
    "  for images, masks in tqdm(data_loader):\n",
    "\n",
    "    images= images.to(DEVICE)\n",
    "    masks = masks.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits,loss = model(images,masks)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  return total_loss/len(data_loader)\n",
    "def eval_fn(data_loader, model):\n",
    "\n",
    "  model.eval()\n",
    "  total_loss=0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images,masks in tqdm(data_loader):\n",
    "\n",
    "      images= images.to(DEVICE)\n",
    "      masks= masks.to(DEVICE)\n",
    "\n",
    "      logits,loss=model(images,masks)\n",
    "\n",
    "      total_loss += loss.item()\n",
    "\n",
    "  return total_loss/len(data_loader)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LR)\n",
    "best_valid_loss = np.Inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "  train_loss = train_fn(trainloader,model,optimizer)\n",
    "  valid_loss = eval_fn(validloader,model)\n",
    "\n",
    "  if valid_loss < best_valid_loss:\n",
    "    torch.save(model.state_dict(),\"best_model.pt\")\n",
    "    print(\"Saved model\")\n",
    "    best_valid_loss = valid_loss\n",
    "\n",
    "  print(f\"Epoch : {i+1} Train_loss : {train_loss} Valid_loss : {valid_loss}\")\n",
    "\n",
    "idx = 20\n",
    "\n",
    "model.load_state_dict(torch.load(\"/content/best_model.pt\"))\n",
    "\n",
    "image, mask = validset[idx]\n",
    "\n",
    "logits_mask = model(image.to(DEVICE).unsqueeze(0)) #(C,H,W)-> (1,C,H,W)\n",
    "\n",
    "pred_mask = torch.sigmoid(logits_mask)\n",
    "\n",
    "pred_mask = (pred_mask>0.5)*1\n",
    "\n",
    "f, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(10,5))\n",
    "        \n",
    "ax1.set_title('IMAGE')\n",
    "ax1.imshow(image[0])\n",
    "\n",
    "ax2.set_title('GROUND TRUTH')\n",
    "ax2.imshow(mask[0],cmap = 'gray')\n",
    "\n",
    "ax3.set_title('GROUND TRUTH')\n",
    "ax3.imshow(pred_mask.detach().cpu().squeeze(0)[0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w * x + b\n",
    "def criterion(yhat,y):\n",
    "    return torch.mean((yhat-y)**2)\n",
    "lr = 0.1\n",
    "LOSS = []\n",
    "def train_model(iter):\n",
    "    \n",
    "    # Loop\n",
    "    for epoch in range(iter):\n",
    "        \n",
    "        # make a prediction\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # calculate the loss \n",
    "        loss = criterion(Yhat, Y)\n",
    "\n",
    "        # Section for plotting\n",
    "        get_surface.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "        if epoch % 3 == 0:\n",
    "            get_surface.plot_ps()\n",
    "            \n",
    "        # store the loss in the list LOSS\n",
    "        LOSS.append(loss)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters slope and bias\n",
    "        w.data = w.data - lr * w.grad.data\n",
    "        b.data = b.data - lr * b.grad.data\n",
    "        \n",
    "        # zero the gradients before running the backward pass\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
